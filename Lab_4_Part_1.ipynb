{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haseebtanvir079/Advanced-DataScience/blob/main/Lab_4_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGIKK4Nn8nOM"
      },
      "source": [
        "CMP7161\n",
        "\n",
        "# Objectives\n",
        "In this lab you will:\n",
        "* Revise basic univariate data analysis techniques to better understand how individual variables / attributes are distributed\n",
        "*\tApply basic bivariate visualisation techniques to better identify the relationships between variables\n",
        "* Apply Pearson's correlation to investigate the linear relationships that may be present amongst variables / attributes in our datasets\n",
        "* Define the nominal / categorical encoding technique \"one-hot\" encoding\n",
        "* Linear Regression\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhX_mk-X8yMZ"
      },
      "source": [
        "# Library imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULdnp8fehquH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Seaborn is a useful library for Data Visualisation\n",
        "from scipy.stats import skewnorm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.graphics.mosaicplot import mosaic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCfpJOCyuMdL"
      },
      "source": [
        "# Data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGhk01Y-seKF"
      },
      "source": [
        "Before going any further please make sure you have created a data_sets folder in Colab and uploaded the following files into it:\n",
        "\n",
        "\n",
        "* This can be found within the [\"datasets.zip\"](https://moodle.bcu.ac.uk/mod/folder/view.php?id=8217579) zip file on Moodle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFRhkgytFAhV"
      },
      "source": [
        "When you are done uploading the files into your Google Drive, click the \"Mount Drive\" icon\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "to mount your Google Drive, and change the relevant filepaths for the below datasets to their equivalents within your Google Drive configuration (remember you can right-click on the file and select \"copy path\" to get the file path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbz2UuY6Gqme"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdThIVNouHiE"
      },
      "outputs": [],
      "source": [
        "# Downloaded from UCI Machine learning repository\n",
        "# https://archive.ics.uci.edu/ml/datasets/iris\n",
        "# \"Data Folder\" -> iris.data\n",
        "# \"Data Folder\" -> iris.names will give us some more data on the attributes\n",
        "\n",
        "df_iris = pd.read_csv('dataset/iris.data',\n",
        "                        names=['SepalLength','SepalWidth','PetalLength','PetalWidth','Species'])\n",
        "df_iris.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSG-Mz35PV33"
      },
      "source": [
        "We'll now use the train-test splitter inside the SKLearn package to give us two subsets of data\n",
        "one for training and one for testing, divided into the\n",
        "features (the X values) and the targets (the Y values)\n",
        "the \\ allows us to have a line break in the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB6szlwRO5sS"
      },
      "outputs": [],
      "source": [
        "X = df_iris.drop(columns = 'Species')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlRU7Sx8PGWo"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1pDsB1bPJ_I"
      },
      "outputs": [],
      "source": [
        "y = df_iris['Species']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph4jZP3sPqEi"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lahFOpJ8Pr-N"
      },
      "outputs": [],
      "source": [
        "# The dataframe with all our test data\n",
        "# we will save this for later\n",
        "df_iris_test = X_test\n",
        "df_iris_test['Species'] = y_test\n",
        "df_iris_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddrvuYBj2S4E"
      },
      "outputs": [],
      "source": [
        "# The dataframe with all our training data\n",
        "# we will use this for EDA\n",
        "# and model building\n",
        "# Note: be careful, the smaller the dataset (in terms of records)\n",
        "# the more likely that the train and test samples might have larger differences\n",
        "df_iris_train = X_train\n",
        "df_iris_train[\"Species\"] = y_train\n",
        "df_iris_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyS75NfhPpS5"
      },
      "source": [
        "We can use the describe() method to obtain valuable statistical information about data within our data frame. When dealing with numeric values it provides attributes such as:\n",
        "\n",
        "\n",
        "*   A count of the amount of items for that variable / column\n",
        "*   The [mean average](https://simple.wikipedia.org/wiki/Mean) for that variable / column\n",
        "*   The [standard deviation](https://simple.wikipedia.org/wiki/Standard_deviation) of that column\n",
        "*   The minimum value found within that variable / column\n",
        "*   The [percentile values](https://simple.wikipedia.org/wiki/Percentile) for that variable / column (25%, 50%, 75%). For more information on percentiles, see [here](https://www.w3schools.com/python/python_ml_percentile.asp)\n",
        "*   The maximum value found within that variable / column\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7ifT-zLPmYM"
      },
      "outputs": [],
      "source": [
        "# Note how there is no description summary for the Species column?\n",
        "# Why do you think this is?\n",
        "df_iris_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HEcT4xTSZUT"
      },
      "outputs": [],
      "source": [
        "# We can include all columns by using the optional argument include with the value 'all'\n",
        "df_iris_train.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noxKJ0W5IbNe"
      },
      "source": [
        "# The \"gist\" of Exploratory Data Analysis\n",
        "\n",
        "Exploratory data analysis is usually the first step to come after data collection before we start to perform any real ML modelling. To understand how to effectively and efficiently handle our data exploring it and drawing out key insights before attempting to represent it to a Machine Learning algorithm is key.\n",
        "\n",
        "## Overall EDA process\n",
        "\n",
        "\n",
        "1.   Ask questions\n",
        "2.   Wrangle the data\n",
        "3.   Explore the data\n",
        "4.   Draw conclusions based on the explorations\n",
        "5.   Communicate those conclusions\n",
        "6.   Repeat 1-5\n",
        "\n",
        "## Asking questions\n",
        "We usually start the analysis process by asking various questions, including but not limited to such questions as:\n",
        "*   What does our data represent?\n",
        "*   What is our goal when exploring the data?\n",
        "*   Why are we going to analyse the data?\n",
        "*   How will we get answers from our data?\n",
        "\n",
        "Let's consider Iris in particular, based on the data we have what kind of specific questions could we ask?\n",
        "*   What is the difference in petal length based on Iris species?\n",
        "*   What is the difference in petal width based on Iris species?\n",
        "*   What is the difference in sepal length based on Iris species?\n",
        "*   What is the difference in sepal width based on Iris species?\n",
        "*   Is a larger petal length positively associated with larger petal width?\n",
        "*   Is a larger sepal length positively associated with a larger sepal width?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## General progression of analysis\n",
        "1.   Familiarise ourselves with the dataset and its variables / attributes\n",
        "  *   What does the data represent?\n",
        "  *   Where does it come from?\n",
        "  *   What is the \"shape\" of the data?\n",
        "    + How many records?\n",
        "    + How many variables / attributes?\n",
        "  *   What variables / attributes are present?\n",
        "  *   How is each variable / attribute currently encoded?\n",
        "  *   What might be an appropriate \"statistical data type\" / \"level of measurement\" to represent each variable / attribute? - we can confirm this with further univariate analysis later on\n",
        "2.   Perform univariate analysis to better understand individual variables / attributes\n",
        "  *   What is the distribution of each variable?\n",
        "  *   List item\n",
        "3. Perform bivariate analysis to better understand the relationships / interactions between variables / attributes\n",
        "4. Perform [correlation analysis](https://simple.wikipedia.org/wiki/Correlation) to understand whether a linear relationship exists between two variables / attributes\n",
        "5. Perform further analysis to answer additional questions that may have arisen from your prior analyses\n",
        "\n",
        "## Why do we need EDA for ML Modelling?\n",
        "As well as being able to understand our data better EDA provides some very important insights when attempting to build an ML model for a supervised learning task.\n",
        "* It can give us valuable insight into how to represent our data to the model (levels of measurement, preprocessing, encoding, standardisation, etc)\n",
        "* To better understand the target variable in question\n",
        "* It can give us insight into how we might need to further clean / transform the data (are there missing values? is data encoded appropriately for its level of measurement? what do we do with highly-correlated features? etc.)\n",
        "\n",
        "## Note\n",
        "We can't possibly cover every possible measure, visualisation plot, etc that could be used for you to explore the data but in this week and the coming weeks we will be introducing you to some common visualisations and \"rules of thumb\" which can be helpful in this process. Fundamentally, when performing EDA you should always ask yourself:\n",
        "* What is this specific data that I am dealing with?\n",
        "* What am I trying to understand about this data?\n",
        "* Is the analysis technique I am applying suitable for the kind of data this is?\n",
        "  * If it isn't could I look into a better approach?\n",
        "* What conclusions can I draw from my analysis?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bnod_SBHxYt"
      },
      "source": [
        "# Univariate analysis\n",
        "\n",
        "We looked at a brief overview of univariate data analysis last week. This is analysis that relates to understanding a single variable, especially in terms of its:\n",
        "*   [Level of measure / Statistical data type](https://en.wikipedia.org/wiki/Level_of_measurement)\n",
        "*   Distribution of values\n",
        "*   etc.\n",
        "\n",
        "Previously we have used plots such as:\n",
        "*   [Boxplots](https://datavizcatalogue.com/methods/box_plot.html) (useful when we want to understand the distribution feautres for numeric values)\n",
        "*   [Histograms](https://datavizcatalogue.com/methods/histogram.html) (useful when we want to understand the \"shape\" of a distribution of numeric values)\n",
        "*   [Countplots](https://datavizcatalogue.com/methods/bar_chart.html) (useful when we wish to get a count of the relative amounts of nominal values)\n",
        "\n",
        "To better understand our single variables. Looking at important statistical measures such as measures of central tendency, measures of data dispersion, percentiles and skewness. The appropriate plots / visualisations to choose for univariate analysis are based on the nature of each variable / attribute under question, we can use our notions of \"level of measurement\" to help guide us to make appropriate decisions for what visualisations are best suited for the kind of data we are dealing with - for example we wouldn't tend to plot a histogram for a nominal variable / attribute.\n",
        "\n",
        "For a better understanding of what other visualisations we could choose, have a look at the [Seaborn documentation](https://seaborn.pydata.org/tutorial/introduction.html), the [Seaborn gallery](https://seaborn.pydata.org/examples/index.html) and the [Data Visualisation Catalogue](https://datavizcatalogue.com/search.html)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvHWgyn7Hxl0"
      },
      "source": [
        "# From Univariate to Multivariate analysis\n",
        "With multivariate analysis we are analysing multiple variables and how they relate to each other. We tend to start this process of with a **bivariate** analysis, comparing two variables to better understand the relationships between them.\n",
        "\n",
        "There are numerous ways that we can slice and dice our data to perform bivariate analysis, for example we can use the following plots to gain a greater amount of information about our variables / attributes under question:\n",
        "*   [Boxplot by category](https://datavizcatalogue.com/methods/box_plot.html) (technically still a Univariate analysis just divided by category)\n",
        "*   [Scatterplot](https://datavizcatalogue.com/methods/scatterplot.html)\n",
        "*   [Pairwise plot](https://seaborn.pydata.org/generated/seaborn.pairplot.html)\n",
        "\n",
        "When performing exploratory data analysis for the purpose of building machine learning models, it is often a good rule of thumb to investigate the relationship between our features (the X values, the attributes we will use to train the model) and our target first (the Y values, the attribute 'labels' we will use to train the model). Then, after establishing a good picture of the relationships between each feature and the target we can look at the relationships, **between features**. We tend to analyse things in this order because, based on us trying to build a supervised ML model that utilises features to predict the relevant target value it can help us greatly to understand whether there are any clear, simple to find, patterns with how a given feature might be associated with a target class (for example do certain species of Iris tend to have smaller petals than others?)\n",
        "\n",
        "For a better understanding of what other visualisations we could choose, have a look at the [Seaborn documentation](https://seaborn.pydata.org/tutorial/introduction.html), the [Seaborn gallery](https://seaborn.pydata.org/examples/index.html) and the [Data Visualisation Catalogue](https://datavizcatalogue.com/search.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2Puuzel_E7Q"
      },
      "source": [
        "## Numerial Feature(s) vs Nominal/ Categorical Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ciuu3BJVcvS"
      },
      "outputs": [],
      "source": [
        "df_iris_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bz2Wm9d48NLS"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = df_iris_train, x = df_iris_train[\"PetalLength\"], y=df_iris_train[\"Species\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNl-78wBNbUC"
      },
      "source": [
        "What can we tell about the relative differences of the distributions for each species by Petal Length in our sample?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZB_53ci8htN"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = df_iris_train, x = df_iris_train[\"PetalWidth\"], y=df_iris_train[\"Species\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZr6SUU9Nj1u"
      },
      "source": [
        "What can we tell about the relative differences of the distributions for each species by Petal Width in our sample?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeDFaObU8kFy"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = df_iris_train, x = df_iris_train[\"SepalLength\"], y=df_iris_train[\"Species\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTGsa69pNmgE"
      },
      "source": [
        "What can we tell about the relative differences of the distributions for each species by Sepal Length in our sample?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-s4JVUv8kki"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = df_iris_train, x = df_iris_train[\"SepalWidth\"], y=df_iris_train[\"Species\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Px1tYPJNoss"
      },
      "source": [
        "What can we tell about the relative differences of the distributions for each species by Sepal Width in our sample?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNaxaM81_K0Z"
      },
      "source": [
        "## Feature(s) vs Feature(s)\n",
        "Let's now compare features with each other, in this case we will be comparing numeric features against each other (because all of Iris' non-target variables / attributes are numeric, specifically **ratio** variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq3xMfJk-9Fx"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='SepalLength', y='SepalWidth',\n",
        "                hue='Species', data=df_iris_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ENgyP6J_jE1"
      },
      "source": [
        "The above scatterplot seems to suggest that:\n",
        "* Setosa has smaller sepal lengths but larger sepal widths than the other species in the sample\n",
        "*Versicolor is roughly in the middle of the other two species in the sample in terms of their sepal length and width, with some overlap\n",
        "* Virginica tends to have greater sepal lengths but smaller sepal widths than setosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm9NbhSv_T7k"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='PetalLength', y='PetalWidth',\n",
        "                hue='Species', data=df_iris_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bdXS1lPAMwr"
      },
      "source": [
        "The above scatterplot seems to suggest that:\n",
        "* Setosa has far smaller petal lengths and widths than the other two species in the sample\n",
        "* Versicolor again seems to lie roughly in the middle of the other two species within the sample in terms of its petal length and width\n",
        "* Virginica has the largest of petal lengths and widths of the species in the sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5g25GQdG29d"
      },
      "source": [
        "We can also produce a [pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html) that contains scatter graphs comparing each variable as well as a plot of the data distribution per Species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KMB2EvrAI7j"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_iris_train,\n",
        "             hue='Species', height=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snHPEccYDd-f"
      },
      "source": [
        "# Correlation analysis\n",
        "\n",
        "[Correlation](https://simple.wikipedia.org/wiki/Correlation) is a measure of the degree to which two variables/attributes possess a linearl relationship. This is very important step in exploratory data analysis of bivariate data. In the broadest sense correlation is actually any statistical relationship, whether [causal](https://simple.wikipedia.org/wiki/Causality) or not, between two variables.\n",
        "\n",
        "Pandas provides three measures of correlation that can be calculated on dataframes:\n",
        "\n",
        "\n",
        "*   [Pearson's correlation](https://simple.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
        "*   [Spearman's](https://simple.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) rank correlation\n",
        "*   Kendall's [rank correlation](https://simple.wikipedia.org/wiki/Rank_correlation)\n",
        "\n",
        "\n",
        "Pearson's is the standard measure of correlation to identify linear relationships between variables and will be the primary focus of our investigation examples currently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuoQvIxWFp4d"
      },
      "outputs": [],
      "source": [
        "?df_iris_train.corr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIGXefl8CdSK"
      },
      "outputs": [],
      "source": [
        "# We can find the pairwise correlation of all attributes in the dataframe by using the corr method\n",
        "# We will select pearson correlation to see if there are any simple\n",
        "# linear relationships that can be identified amongst variables\n",
        "df_iris_corr = df_iris_train.corr(method='pearson')\n",
        "df_iris_corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyvi696_HalO"
      },
      "source": [
        "Now let's create a heatmap to visualise these results.\n",
        "A video on using heatmap plots to visualise correlations within Seaborn can be found [here](https://www.youtube.com/watch?v=J7cd1-g1O7A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1AvONK4Ct6B"
      },
      "outputs": [],
      "source": [
        "# We can generate a heatmap to visualise the pairwise correlations of these variables\n",
        "# The diagonal gives us a pearson correlation of '1'\n",
        "# which shows that the variables are perfectly correlated\n",
        "# this is to be expected as we are comparing variables agains themselves\n",
        "\n",
        "# The highly correlated variables\n",
        "# (assuming that \"high correlation\" means a pearson value of >= 0.7)\n",
        "# are:\n",
        "# Petal Length and Petal Width\n",
        "# Sepal Length and Petal Length\n",
        "# Sepal Length and Petal Width\n",
        "sns.heatmap(df_iris_corr, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6lUTN_RH4tN"
      },
      "source": [
        "# Data Pre-processing\n",
        "When we start building our machine learning models proper, we will be utilising various data [pre-processing](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) techniques to **clean**, **transform** and **reduce** our data to make it more appropriate for training supervised learning models.\n",
        "\n",
        "The general process of data pre-processing can be grouped into four parts:\n",
        "1.   Data Cleaning\n",
        "  * Handling Missing Data\n",
        "  * Handling Noisy data\n",
        "  * Handling Outliers\n",
        "2.   Data Transformation\n",
        "  * Encoding\n",
        "  * Scaling\n",
        "3.   Data reduction\n",
        "  * Reducing dimensions of our data\n",
        "4.   Assess quality of data\n",
        "\n",
        "For today's lab we will focus on two aspects of this, before we cover it in more depth in the coming weeks:\n",
        "\n",
        "\n",
        "*   Identifying missing data for a variable / attribute\n",
        "*   Encoding nominal variables / attributes for appropriate representation to the ML algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb6b5qjiF7MR"
      },
      "source": [
        "## Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQC6PNyrF4YV"
      },
      "outputs": [],
      "source": [
        "df_iris.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk2iKQQAGEot"
      },
      "outputs": [],
      "source": [
        "df_iris"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRzlaHTLPXAs"
      },
      "source": [
        "## Encoding of nominal variables\n",
        "Remember the \"levels of measurement\" that we introduced previously? Well one of the many ways that understanding levels of measurement / statistical data types is useful is when we wish to represent our data to Machine Learning models.\n",
        "\n",
        "For example, take the \"Species\" attribute of the Iris data set, we have three distinct nominal category values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8KSnfzCVyVt"
      },
      "outputs": [],
      "source": [
        "df_iris[\"Species\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOtilXSvWEwu"
      },
      "outputs": [],
      "source": [
        "df_iris.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui3F6ZFUWFf1"
      },
      "source": [
        "For people this kind of representation of the data is fine, we have our individual feature variables and our target variable \"Species\" is a nominal variable where we can tell from a glance what category each record belongs to (in other words, what species each row is a member of).\n",
        "\n",
        "\n",
        "But in Machine Learning this way of representing our data can sometimes cause problems.\n",
        "\n",
        "Below are some common ways of encoding nominal values:\n",
        "* [One hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
        "* Dummy variable encoding\n",
        "* Hash encoding\n",
        "\n",
        "We will explore more on these encodings in the coming weeks when we are building **regression** and **classification** models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BofO4NrPMAu8"
      },
      "source": [
        "# A taster example: Iris EDA\n",
        "\n",
        "Let's consider Iris in particular, based on the data we have what kind of specific questions could we ask?\n",
        "*   What is the difference in petal length based on Iris species?\n",
        "*   What is the difference in petal width based on Iris species?\n",
        "*   What is the difference in sepal length based on Iris species?\n",
        "*   What is the difference in sepal width based on Iris species?\n",
        "*   Is a larger petal length positively associated with larger petal width?\n",
        "*   Is a larger sepal length positively associated with a larger sepal width?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlndIBQRMEsV"
      },
      "outputs": [],
      "source": [
        "# Downloaded from UCI Machine learning repository\n",
        "# https://archive.ics.uci.edu/ml/datasets/iris\n",
        "# \"Data Folder\" -> iris.data\n",
        "# \"Data Folder\" -> iris.names will give us some more data on the attributes\n",
        "\n",
        "df_iris = pd.read_csv('/content/drive/MyDrive/CMP7161/datasets/iris.data',\n",
        "                        names=['SepalLength','SepalWidth','PetalLength','PetalWidth','Species'])\n",
        "df_iris.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhfII2PdXJOk"
      },
      "outputs": [],
      "source": [
        "# We'll now use the train-test splitter inside the SKLearn package to give us two subsets of data\n",
        "# one for training and one for testing, divided into the\n",
        "# features (the X values) and the targets (the Y values)\n",
        "# the \\ allows us to have a line break in the code\n",
        "X = df_iris.drop(columns = ['Species'], axis = 1)\n",
        "y= df_iris['Species']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F10yBwb5XlQy"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE_b4VI2Xnv5"
      },
      "outputs": [],
      "source": [
        "# The dataframe with all our test data\n",
        "# we will save this for later\n",
        "df_iris_test = X_test\n",
        "df_iris_test[\"Species\"] = y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4C65xBYXZSE"
      },
      "outputs": [],
      "source": [
        "# The dataframe with all our training data\n",
        "# we will use this for EDA\n",
        "# and model building\n",
        "# Note: be careful, the smaller the dataset (in terms of records)\n",
        "# the more likely that the train and test samples might have larger differences\n",
        "df_iris_train = X_train\n",
        "df_iris_train[\"Species\"] = y_train\n",
        "df_iris_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VuJMgVxMIv3"
      },
      "outputs": [],
      "source": [
        "# What is the shape of the dataset?\n",
        "# Iris has 150 records with 5 attributes\n",
        "df_iris.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJPKNZEuX2bZ"
      },
      "outputs": [],
      "source": [
        "# What are the names of those attributes\n",
        "# and what are the programming types that they are encoded as?\n",
        "\n",
        "# We could check this using dtypes\n",
        "df_iris.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJf28aisMQve"
      },
      "outputs": [],
      "source": [
        "# But the info method often gives us more information\n",
        "# Including the amount of non-null values for each variable\n",
        "df_iris.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEKhU0l_Vekp"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the first 10 records\n",
        "df_iris.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwuMboHJM8bn"
      },
      "source": [
        "What can we tell about the Iris data set from our analysis so far?\n",
        "\n",
        "\n",
        "*   There are 150 instances / records\n",
        "*   There are 5 attributes / variables / columns\n",
        "*   No columns contain null values\n",
        "*   Four of our columns are encoded with numeric programming types, all of them being 64 bit floating point numbers (double)\n",
        "*   A single column is encoded as an \"object\" type, this is likely to contain nominal / categorical data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzOwPGPlXlm4"
      },
      "outputs": [],
      "source": [
        "# Now let's look at our training subset\n",
        "df_iris_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RBWi5kwMqF1"
      },
      "outputs": [],
      "source": [
        "# Viewing some basic statistics for the Iris data set\n",
        "df_iris.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyw3CZeuSaNA"
      },
      "source": [
        "What insights have we obtained so far?\n",
        "* The amount of non-null values for each numeric attribute\n",
        "* The mean average value for each numeric attribute\n",
        "* The standard deviation (a measure of dispersion) for each attribute\n",
        "  * In particular, we can note that the attribute with the largest std dev is Petal length, suggesting that the values for this attribute should be quite widely spread out / **dispersed**\n",
        "* The minimum value for each attribute\n",
        "* The 25th, 50th (median) and 75th percentiles for each attribute\n",
        "  * 75% of the data for Petal Width seems to fall between 0.1 and 1.8 cm\n",
        "* The maximum value for each attribute\n",
        "  * Notice how petal width seems to have both the smallest minimum value and the smallest maximum value?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV7fLQqnTPL2"
      },
      "outputs": [],
      "source": [
        "# Let's now check to see if any records are duplicated (have the same values)\n",
        "df_iris[df_iris.duplicated()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qfmsDi-WG4o"
      },
      "source": [
        "We have 3 duplicated records, sometimes duplicated records can lead to problems (especially in the case when there are imbalances in the amount of records for each target class when dealing with classification problems)\n",
        "\n",
        "Further discussion can be found [here](https://www.site.uottawa.ca/~nat/Workshop2003/imbalance-kolcz.pdf) and [here](https://stats.stackexchange.com/questions/283170/when-is-unbalanced-data-really-a-problem-in-machine-learning?noredirect=1&lq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVeGF8g8WN7_"
      },
      "outputs": [],
      "source": [
        "# Let's check whether our nominal attributes are \"balanced\"\n",
        "# (i.e. do we have roughly the same amount of records for each category?)\n",
        "df_iris[\"Species\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rLcCoPIWc31"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data = df_iris, x =\"Species\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A71AzkgfobP2"
      },
      "source": [
        "So it seems the species classes are balanced (with each class having 50 records).\n",
        "\n",
        "How about our training set?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OKHnt7D4515"
      },
      "outputs": [],
      "source": [
        "df_iris_train[\"Species\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4yv27z542RQ"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data = df_iris_train, x = \"Species\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jOvqH7L6NrT"
      },
      "source": [
        "A \"roughly\" balanced spread, no nominal category seems to be too heavily represented in comparison to others (at least at a glance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvQVMC_mokNJ"
      },
      "source": [
        "Now let's have a look at some of the individual feature variables by performing some univariate analysis on our training sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG9G-pVZ5KID"
      },
      "outputs": [],
      "source": [
        "# The overall distribution across all classes\n",
        "sns.boxplot(df_iris_train[\"PetalLength\"], orient='h')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJmLaBhj7BEH"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EU_ZNh_4vGR"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = df_iris_train, x = df_iris_train[\"PetalLength\"], y=df_iris_train[\"Species\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NEJzA6m7HMa"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ9KzRBz4vPB"
      },
      "outputs": [],
      "source": [
        "# The overall distribution across all classes\n",
        "sns.boxplot(df_iris_train[\"PetalWidth\"], orient ='h')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfQ_aIWh7I8d"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LghbnjH5UlP"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = df_iris_train, x = df_iris_train[\"PetalWidth\"], y=df_iris_train[\"Species\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RqZTFgj7KGi"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSTeqcZY4vXY"
      },
      "outputs": [],
      "source": [
        "# The overall distribution across all classes\n",
        "sns.boxplot(df_iris_train[\"SepalLength\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEaUkv_n7K9h"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OT51FVl5U9X"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data= df_iris_train, x = \"SepalLength\", y=\"Species\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AJsVPab7MuP"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_LNUUQw4vfP"
      },
      "outputs": [],
      "source": [
        "# The overall distribution across all classes\n",
        "sns.boxplot(df_iris_train[\"SepalWidth\"]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgNbx8D-7NvN"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkIUX7v95VZw"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data = df_iris_train, x =  df_iris_train[\"SepalWidth\"], y=df_iris_train[\"Species\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZMhBYRi7Oqc"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jdPVwcy544i"
      },
      "source": [
        "Let's now look at some bivariate analysis, investigating the relationship between different features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb1NPO3doszb"
      },
      "outputs": [],
      "source": [
        "plt.title(\"Sepal Length and Sepal Width by Iris Species\")\n",
        "sns.scatterplot(data = df_iris_train,\n",
        "                x = df_iris_train['SepalLength'],\n",
        "                y = df_iris_train['SepalWidth'],\n",
        "                hue=df_iris_train['Species'], s=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7Qw65vz7QOQ"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fLhmXxbpl9-"
      },
      "outputs": [],
      "source": [
        "plt.title(\"Petal Length and Petal Width by Iris Species\")\n",
        "sns.scatterplot(data = df_iris_train,\n",
        "                x = df_iris_train['PetalLength'],\n",
        "                y = df_iris_train['PetalWidth'],\n",
        "                hue=df_iris_train['Species'], s=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6opWdW57ddy"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psDk8F-N61Zf"
      },
      "source": [
        "We could use a pairplot to view the comparisons between our attributes in one plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7ecrGAzp6fk"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_iris_train,hue=\"Species\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtDubz3l7f1q"
      },
      "source": [
        "What does this tell us about the data being investigated?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRM8QMNQ7ieJ"
      },
      "source": [
        "Now let's look for correlations in our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yepI0gYKqbDA"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(df_iris_train.corr(), annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnIG8oGN7qlM"
      },
      "source": [
        "Now let's look for correlations in our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UK7xWJuH1Js"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjgLHTW3H-DC"
      },
      "source": [
        "## Exercise 1\n",
        "\n",
        "Were we able to produce some possible valuable answers / insights to our previously stated questions about the Iris data set based on our limited EDA example above? Justify your answer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZoSas-8xDYi"
      },
      "source": [
        "### Sample answers / Tutor comments\n",
        "\n",
        "Students will want to consider whether the above basic investigation provides sufficient insight when attempting to answer the following questions:\n",
        "\n",
        "*   What is the difference in petal length based on Iris species?\n",
        "*   What is the difference in petal width based on Iris species?\n",
        "*   What is the difference in sepal length based on Iris species?\n",
        "*   What is the difference in sepal width based on Iris species?\n",
        "*   Is a larger petal length positively associated with larger petal width?\n",
        "*   Is a larger sepal length positively associated with a larger sepal width?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAFL-fzisEkJ"
      },
      "source": [
        "## Sample Answer\n",
        "\n",
        "<details><summary>Click here for the solution</summary>\n",
        "Looking at the EDA completed for the Iris data set, there are some valuable results which we can use to answer the previously asked questions.\n",
        "\n",
        "#### What is the difference in petal length based on Iris species?\n",
        "Using the box plot of the training data, we can clearly see differences in the petal length based on the species of iris. In particular, values for the setosa species are clearly distinct from the other two species.\n",
        "\n",
        "Virginica and versicolor species see an overlap in petal length, though the standard deviation range of each is distinct.\n",
        "\n",
        "Setosa has petal lengths from around 1.2-1.6cm, with a vary small range of possible values. Versicolor has petal lengths from 3.2-5.1cm, with virginica from 4.5-6.5cm.\n",
        "\n",
        "#### What is the difference in petal width based on Iris species?\n",
        "The box plot shows clear differences between the petal width, based on the Iris species. Again, the setosa species in particular is clearly distinct from the other two.\n",
        "\n",
        "Verginica and versicolor have petal widths closer to one-another, though the middle 75% of the data for each are distinct from one another.\n",
        "\n",
        "#### What is the difference in sepal length based on Iris species?\n",
        "From our box plot, we can see a greater degree of overlap between sepal length and species. This is particularly true comparing virginica and versicolor species, which have similar minimum values and overlapping standard deviation ranges.\n",
        "\n",
        "Setosa has vales from 4.5-5.5cm, versicolor from 4.8-7cm, and virginica from 4.8-7.8cm.\n",
        "\n",
        "#### What is the difference in sepal width based on Iris species?\n",
        "The range of values for sepal width across all values is quite small, from 2-4.5cm.\n",
        "\n",
        "From the box plot, we can see a large overlap between versicolor and virginica, though versicolor generally has a lower value for sepal width out of the two. Setosa, on average, has the largest sepal width.\n",
        "\n",
        "The range of values for setosa is 2.8-4.8cm, virginica from 2.5-3.7cm, and versicolor from 2-3.3cm.\n",
        "\n",
        "#### Is a larger petal length positively associated with larger petal width?\n",
        "Our scatter plot comparing petal length and width suggests there is positive correlation between the two. This is confirmed in our heatmap, which gives a value of 0.96 for the correlation between these two series.\n",
        "\n",
        "We can conclude that a larger petal length is positively associated with larger petal width.\n",
        "\n",
        "#### Is a larger sepal length positively associated with a larger sepal width?\n",
        "The scatter plot of the sepal length vs width shows little trend; certainly, a trend is not noticable.\n",
        "\n",
        "The heatmap gives a very small negative correlation, which indicates there is little to no association between the two series.\n",
        "\n",
        "Therefore, we can conclude that a larger sepal width is not positively correlated with sepal length.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFT0hVStIA6f"
      },
      "source": [
        "## Exercise 2\n",
        "\n",
        "In terms of nominal / categorical variables, what is a [mosaic plot](https://datavizcatalogue.com/methods/marimekko_chart.html) and why would it be a useful visualisation when dealing with nominal values?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kcAh5BtxIMY"
      },
      "source": [
        "### Sample answers / Tutor comments\n",
        "Key points students answers could make:\n",
        "* Mosaic plots / Marimekko plots allow us to visualise pairs of nominal / categorical variables.\n",
        "* We can detect relationships between categories and subcategories based on the data plotted on the two axes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGeGYKFMsusa"
      },
      "source": [
        "\n",
        "\n",
        "<details><summary>Click here for the solution</summary>\n",
        "A mosaic plot, or Marimekko chart, plots data for two variables across multiple series. It allows multiple comparisons to be made between categorical data in a single plot.\n",
        "\n",
        "The width of each series in the plot can be used to compare the value count between the two, with the stacked bar splitting the series into a count of each of the values present for this series. This gives an overview of the distribution of values within the series. Comparing this to a second series can highlight differences between the two, and indicate the distribution of values through the data set.\n",
        "\n",
        "Nominal data is categorical data that doesn't not have any order, which excludes many comparisons and plot types. This makes the mosaic plot a useful option for comparing nominal data.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9KArA4hs6f8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSS8gl0BIBHy"
      },
      "source": [
        "## Exercise 3\n",
        "\n",
        "What is the difference between the kinds of linear relationships that Pearson's correlation is capable of modelling with the kind of relationships that Spearman's rank correlations are capable of modelling?\n",
        "\n",
        "Hint: the following [link](https://towardsdatascience.com/clearly-explained-pearson-v-s-spearman-correlation-coefficient-ada2f473b8) may help to explain some more of the basics\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5owQyDuxJcn"
      },
      "source": [
        "### Sample answers / Tutor comments\n",
        "\n",
        "Students should produce an answer that discusses:\n",
        "* Pearson's use for modelling the linear relationships between variables - the more keen may also discuss the normal distribution / parametric assumptions.\n",
        "* When discussing Spearman's correlation they should mention that it allows us to capture a monotonic relationship between variables\n",
        "* Spearman is a rank correlation measure and therefore deals with the values being rank ordered instead of the specific raw base values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzwNUmBjtAPh"
      },
      "source": [
        "\n",
        "<details><summary>Click here for the solution</summary>\n",
        "\n",
        "\n",
        "Pearson's correlation is only capable of analysing the linearity of the relationship between two series. When one value changes, Pearson's correlation models the change seen in the other value.\n",
        "\n",
        "Spearman's rank works where correlation is linear, but also works on data with a monotonic relationship. That is, data where the size of the value change can be variable. It is therefore more concerned about the overall direction of change through the data set, than the proportionality between the two axis.\n",
        "\n",
        "A Spearman's correlation value that is greater than the Pearson's correlation value could indicate a logarithmic data set, which could be normalised to produce a more linear data set to work with later on.\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLQHtK_hIBe6"
      },
      "source": [
        "## Exercise 6\n",
        "\n",
        "Choose one of the datasets you have created train / test splits for and attempt to create your own exploratory data analysis of them using the training sample.\n",
        "\n",
        "You should:\n",
        "*   Show the shape of the sample training dataset being used and compare this with the shape of the overall dataset\n",
        "*   Perform univariate analysis to better understand the \"target\" variable of the dataset (the variable that we would try to predict in a supervised learning problem)\n",
        "*  Perform univariate analysis to better understand the \"feature\" variables of the dataset (the variables that would be provided to the machine learning model when trying to predict the target)\n",
        "*   Consider what levels of measurement would be appropriate choices for each of the variables / attributes\n",
        "*   Come up with at least 3 questions you could ask / explore about the data that allows you to understand the relationship of a feature variable with the target\n",
        "*   Come up with at least 2 questions you could ask / explore about the data that allows you to understand the relationship between a pair of feature variables\n",
        "*   Attempt to answer those questions using a combination of univariate analysis, multivariate analysis and correlation analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SukIxCAQytqJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdwG--AeIBla"
      },
      "source": [
        "## Exercise 7\n",
        "Present your findings to at least one other student and review their EDA work also (this could be using a different data set).\n",
        "\n",
        "Try to identify at least 2 questions you ask about your colleagues dataset that have not been noted / answered by your colleague's EDA\n",
        "\n",
        "What techniques might you use to investigate these questions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9dW5UqBxOTq"
      },
      "source": [
        "### Sample answers / Tutor comments\n",
        "An opportunity for [Peer learning](https://en.wikipedia.org/wiki/Peer_learning), prompt them to share ideas / understanding of the data and topics at hand with each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q85w7c_eZK-E"
      },
      "source": [
        "## Exercise 8\n",
        "What kind of questions could you ask about your own coursework dataset?\n",
        "  * What kind of relationships could you try to investigate between features and the target?\n",
        "  * What kind of relationships could you try to investigate between various features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nYlyA3A1r2S"
      },
      "source": [
        "### Sample answers / Tutor comments\n",
        "Use the opportunity to discuss with the students how they are approaching EDA with their dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S74AHJZwnhV0"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efwXUjUCoZya"
      },
      "source": [
        "## Description :\n",
        "The goal of this Task is to use the `sklearn` package to fit a **Linear Regression** on [`advertising.csv`](https://moodle.bcu.ac.uk/mod/resource/view.php?id=8113210) datafile.\n",
        "\n",
        "\n",
        "\n",
        "## Data Description:\n",
        "\n",
        "## Instructions:\n",
        "- Use `train_test_split()` function to split the dataset into training and testing sets\n",
        "- Use the `LinearRegression` function to make a model\n",
        "- Fit the model on the training set\n",
        "- Predict on the testing set using the fit model\n",
        "- Estimate the fit of the model using `mean_squared_error` function\n",
        "- Plot the dataset along with the predictions to visualize the fit\n",
        "\n",
        "## Hints:\n",
        "\n",
        "<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\" target=\"_blank\">pd.read_csv(filename)</a>\n",
        "Returns a pandas dataframe containing the data and labels from the file data\n",
        "\n",
        "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" target=\"_blank\">sklearn.train_test_split()</a>\n",
        "Splits the data into random train and test subsets\n",
        "\n",
        "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\" target=\"_blank\">sklearn.LinearRegression()</a>\n",
        "LinearRegression fits a linear model\n",
        "\n",
        "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit\" target=\"_blank\">sklearn.fit()</a>\n",
        "Fits the linear model to the training data\n",
        "\n",
        "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict\" target=\"_blank\">sklearn.predict()</a>\n",
        "Predict using the linear model\n",
        "\n",
        "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error\" target=\"_blank\">mean_squared_error()</a>\n",
        "Computes the mean squared error regression loss\n",
        "\n",
        "<a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\" target=\"_blank\">plt.plot()</a>\n",
        "Plot y versus x as lines and/or markers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJQ5KQkqnktA"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAgJjVlKrAE_"
      },
      "outputs": [],
      "source": [
        "# Read the data from the file \"Advertising.csv\"\n",
        "df = pd.read_csv('dataset/advertising.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1qDxqj4rMg0"
      },
      "outputs": [],
      "source": [
        "# Take a quick look at the data\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf6nTSlA8gld"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU8nlod98xTK"
      },
      "source": [
        "## Simple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg2YgNHl8scH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(df['TV'], df['Sales'], c = 'black')\n",
        "plt.xlabel(' Money spent on TV ads ($)')\n",
        "plt.ylabel('Sales ($)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClOeaItd-gDv"
      },
      "outputs": [],
      "source": [
        "# X = data['TV'].values.reshape(-1,1)\n",
        "# y = data['sales'].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGeqyF2jsca6"
      },
      "outputs": [],
      "source": [
        "# Assign TV advertising as predictor variable 'X'\n",
        "X = df[['TV']]\n",
        "\n",
        "# Set the Sales column as the response variable 'y'\n",
        "y = df['Sales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9WP5L9NsfoF"
      },
      "outputs": [],
      "source": [
        "# Split the dataset in train and test data with 80% training set\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKvgCumWs1E5"
      },
      "outputs": [],
      "source": [
        "# Initialize a Linear Regression model using Sklearn\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the linear model on the train data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Peedict on the test data using the trained model\n",
        "y_pred = model.predict(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3AVKkdZs_HC"
      },
      "outputs": [],
      "source": [
        "### edTest(test_mse) ###\n",
        "# Compute the MSE of the predicted test values\n",
        "mse = mean_squared_error(y_pred, y)\n",
        "\n",
        "# Print the computed MSE\n",
        "print(f'The test MSE is {mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgQFtTBw_wml"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(X, y)\n",
        "# Make a plot of the data along with the predicted linear regression\n",
        "\n",
        "plt.plot(X, y_pred, c = 'blue', linewidth = 2)\n",
        "plt.xlabel(' Money spent on TV ads ($)')\n",
        "plt.ylabel('Sales ($)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7wszclxtpwD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52EJQJeBDEKn"
      },
      "source": [
        "# Additional Challenges\n",
        "\n",
        "Please assess the previously mentioned linear regression using a dataset of your own choice, such as the [car_price](https://moodle.bcu.ac.uk/mod/resource/view.php?id=8113211) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHdH5BvZDkYu"
      },
      "outputs": [],
      "source": [
        "# import all necessary packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okuvAoe9F5XI"
      },
      "outputs": [],
      "source": [
        "# load data to a dataframe\n",
        "df = pd.read_csv('dataset/car_price.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HycTWQXvFsaT"
      },
      "outputs": [],
      "source": [
        "# check the shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiewkjPfF1MV"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5ELbrJNGKm6"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL658MD_GLoE"
      },
      "outputs": [],
      "source": [
        "# check unique data for each feature in the data frame\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPBGjj8LGUZ5"
      },
      "outputs": [],
      "source": [
        "# columns names of the dataframe\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA5cuWnvGgLV"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPohaf_uGrX-"
      },
      "source": [
        "### Now, we can prepare the data for the linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42-fMOYSHG7k"
      },
      "outputs": [],
      "source": [
        "df['enginesize'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj_4sJltGoNo"
      },
      "outputs": [],
      "source": [
        "# create a new simple dataframe using the existing one\n",
        "df = df[['enginesize', 'price']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlEZz9X5HTd3"
      },
      "outputs": [],
      "source": [
        "# check the distribution of data by plotting a scatter\n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.scatter(x = df['enginesize'], y = df['price'])\n",
        "plt.xlabel('enginesize')\n",
        "plt.ylabel('price')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw8aUeW9JUf7"
      },
      "outputs": [],
      "source": [
        "# define X and y\n",
        "X = df['enginesize']\n",
        "y = df['price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnVR_sQMKVBW"
      },
      "outputs": [],
      "source": [
        "# Linear Regression Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnCzKbYXKrtG"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.20,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pba7TXohK2sK"
      },
      "outputs": [],
      "source": [
        "# Shapes of splitted data - sizes of the X_train and y_train should be same. Also test.\n",
        "print('X_train: ', X_train.shape)\n",
        "print('X_test: ', X_test.shape)\n",
        "print('y_train: ', y_train.shape)\n",
        "print('y_test: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NV3sp72Nos1"
      },
      "outputs": [],
      "source": [
        "# create a linear regression model\n",
        "clf = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsriwstBOW2Y"
      },
      "outputs": [],
      "source": [
        "# train the model using training data\n",
        "# since we have only one independent variable, we should use 'values.reshpae(-1,1)\n",
        "X_train = X_train.values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGcN9YOROXbj"
      },
      "outputs": [],
      "source": [
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0sCKVlzOXe7"
      },
      "outputs": [],
      "source": [
        "# print coefficient\n",
        "clf.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWosWSatOXh2"
      },
      "outputs": [],
      "source": [
        "# print y_intercept | bias\n",
        "clf.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnS9UPPuOXkV"
      },
      "outputs": [],
      "source": [
        "# make predictions using test data\n",
        "y_pred = clf.predict(X_test.values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiumFeq-OXnI"
      },
      "outputs": [],
      "source": [
        "# Let's calculate the metrics\n",
        "# Means Squared Error (MSE)\n",
        "mse = mean_squared_error(y_pred, y_test)\n",
        "print(\"MSE ----> \", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9bCV7c6OXpf"
      },
      "outputs": [],
      "source": [
        "# Root Mean Squared Error (RMSE)\n",
        "import math\n",
        "rmse = math.sqrt(mse)\n",
        "print('RMSE ----- > ', rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MyUvLaaQYgY"
      },
      "outputs": [],
      "source": [
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_pred, y_test)\n",
        "print('MAE == > ', mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWDXcSzuQrO2"
      },
      "outputs": [],
      "source": [
        "# R squared (R2)\n",
        "r2 = r2_score(y_pred, y_test)\n",
        "print('R2 ----> ', r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUnBRlfrQ5SC"
      },
      "outputs": [],
      "source": [
        "# print them all\n",
        "print(\"MSE ----> \", mse)\n",
        "print('RMSE ----- > ', rmse)\n",
        "print('MAE == > ', mae)\n",
        "print('R2 ----> ', r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfPhH8YyRNQS"
      },
      "outputs": [],
      "source": [
        "# plot actual and predicted values\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEpPQRV6SRvM"
      },
      "outputs": [],
      "source": [
        "?sns.regplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMhw-wmXRvGz"
      },
      "outputs": [],
      "source": [
        "# plot regression model line\n",
        "sns.regplot(x = y_test, y = y_pred, color= 'blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp9795zVTDue"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE7QBCuvSJ0e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}